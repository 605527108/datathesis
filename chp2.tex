\chapter{相关算法及Hadoop分布式数据处理}
本文提出的推荐系统基于语义分析、协同过滤算法、Hadoop和MapReduce等几个基本算法及基本概念。
以下简单介绍这几个算法及概念。

\section{语义分析}
为了从用户上网流量记录中分析用户的兴趣爱好，我们需要通过语义分析的方法对用户曾经浏览过的网页进行标记和分类。
语义分析包含以下主要步骤：
\begin{enumerate}
	\item 句尾检测

	这一步主要是把一段文字分成一个有意义句子的集合\parencite{kiss2006unsupervised}。
	因为句子一般都含有思想的逻辑单元，所以句子的语法是可以预测的。
	而切词工作是建立在单个句子上的，所以分析文章一般从句尾检测开始。
	
	\item 切词
	
	这一步主要在单个句子上进行操作，将句子分为单个词。
	切词工作对于不同的文字有不同的切法，比如英文切词工作主要按空格切分，但还要注意不能混淆点号的意义；
	而中文没有空格，切词时要按照语料库是否存在该词来切分。

	\item 词义类型标记

	这一步主要是在切好的词语中标记词语的类型，比如是动词还是名词或者是长名词中的一部分。
	对于社交网络中的语言，比如推特或者微博，语言比较口语化，会出现大量动词名词混用情况\parencite{Gimpel2011Part,Owoputi2015Improved,Derczynski2013Twitter}。
	通过标记，机器甚至能指出名词或者是长名词是属于什么类型，比如是人，地点，或者组织。
	
	\item 分块
	
	这一步主要是在有逻辑意义的整句和复合标记的基础上分析词语。
	根据预先定义好的语法，将标记了类型的词语分成块。

	\item 提取主要内容

	这一步主要是进一步为分好的块标记名称或者类型，这与第三步词义类型标记不同，因为这一步以块为整体标记名称或者类型。
\end{enumerate}

其中每一步都很关键，因为一旦其中一步出错，误差会逐步传播，使得语义分析出严重错误。语义分析可以用经典的F1 score来计算其准确程度。下面简单介绍计算F1 score方法。在语义分析完成后，统计以下数量：
\begin{center}
\begin{itemize}
	\item $TP$：被正确识别为实体的词语
	\item $FP$：本来不应该被正确识别为实体的但确实被正确识别为实体的词语
	\item $TN$：本来不应该被正确识别为实体的，同时没有被正确识别为实体的词语
	\item $FN$：本来应该被正确识别为实体的，但没有被正确识别为实体的词语
\end{itemize}
\end{center}
此时再定义精确度$precision$与召回率$recall$如下：
\begin{equation}
precision= \frac{TP}{TP+FP}
\end{equation}
\begin{equation}
recall= \frac{TP}{TP+FN}
\end{equation}
则可以用下式来描述语义分析模型的准确度为
\begin{equation}
F= 2* \frac{precision*recall}{precision+recall}
\end{equation}
\section{协同过滤算法}
协同过滤算法基于三个假设：人们有共同的兴趣爱好；他们的兴趣爱好是稳定的；可以根据兴趣爱好的历史数据预测用户的选择。
协同过滤算法主要比较用户之间的行为，找到最近的相邻用户，根据最近的相邻用户的行为预测用户的兴趣爱好。

对于$m$个用户的用户集$U$，和$n$个物品的物品集$I$，用户$u_i \in U$与物品$i_j \in I$的交互信息记录为一个数值$r_{ij} \in R$。
若用户$i$对物品$j$无交互行为，则$r_{ij}=?$。
最基本的协同过滤算法所研究的问题为：基于$R$，给每位用户推荐一个不包含该用户已经评价过物品的列表，其中的物品按照符合用户兴趣程度递减排序。

协同过滤算法能分为主要两个步骤：第一步是计算用户$x$与用户$y$之间的相似程度：
\begin{equation}
S_{x,y} = \frac{\sum_{i\in I_{xy}}(r_{x,i}-\bar{r}_x)(r_{y,i}-\bar{r}_y)}{\sqrt{\sum_{i\in I_{xy}}(r_{x,i}-\bar{r}_x)^2}\sqrt{\sum_{i\in I_{xy}}(r_{y,i}-\bar{r}_y)^2}}
\end{equation}
其中$r_{x,i}$为用户$x$对物品$i$的评分，$\bar{r}_x$是用户$x$的平均评分，$I_{xy}$为与用户$x$和用户$y$曾发生交互行为的物品集。

第二步计算用户$u$对物品$i$评分的预测值$r_{u,i}$：
\begin{equation}
r_{u,i} = \bar{r}_u + \frac{\sum_{u'\in U^k}(r_{u',i}-\bar{r}_{u'})S_{u,u'}}{\sum_{u'\in U^k}S_{u,u'}}
\end{equation}
其中$U^k$为与用户$u$距离最近的$n$个用户。
最后，只需从物品集中筛选出预测分数前几的物品，推荐给用户$u$。

\section{Hadoop和MapReduce}
Hadoop的基础组件是Hadoop分布式文件系统(HDFS)。
HDFS的机制是将大量数据分布到计算机集群上，数据一次写入，但可以多次读取用于分析。
Hadoop的主要执行框架即MapReduce。
对于保存在分布式文件系统的数据，MapReduce在每个数据节点上进行本地运算。
\def\HDFSfront{
	\path (0,0) node(Splitn) [rectangle,draw] {Split(n)}
			(0,1) node {$\cdots$}
			(0,2) node(Split3) [rectangle,draw] {Split(3)}
			(0,3) node(Split2) [rectangle,draw] {Split(2)}
			(0,4) node(Split1) [rectangle,draw] {Split(1)}
			(0,5.5) node {\textbf{HDFS}};
	\draw (-1,-1) rectangle (1,6);
}
\def\HDFSend{
	\path (10,0) node(Partn) [rectangle,draw] {Part(n)}
			(10,1) node {$\cdots$}
			(10,2) node(Part3) [rectangle,draw] {Part(3)}
			(10,3) node(Part2) [rectangle,draw] {Part(2)}
			(10,4) node(Part1) [rectangle,draw] {Part(1)}
			(10,5.5) node {\textbf{HDFS}};
	\draw (9,-1) rectangle (11,6);
}
\def\mapper{
	\path (3.5,-1) node(Mapper4) [rectangle,draw] {\textbf{Mapper}}
			(3.5,0.5) node {$\cdots$}
			(3.5,2) node(Mapper3) [rectangle,draw] {\textbf{Mapper}}
			(3.5,3.5) node(Mapper2) [rectangle,draw] {\textbf{Mapper}}
			(3.5,5) node(Mapper1) [rectangle,draw] {\textbf{Mapper}};
}
\def\reducer{
	\path (7,1) node(Reducer2) [rectangle,draw] {\textbf{Reducer}}
			(7,2.5) node {$\cdots$}
			(7,4) node(Reducer1) [rectangle,draw] {\textbf{Reducer}};
}
\begin{center}
\begin{tikzpicture}
\HDFSfront
\mapper
\reducer
\HDFSend
\draw[->] (Split1.east) -- (Mapper1.west);
\draw[->] (Split2.east) -- (Mapper2.west);
\draw[->] (Split3.east) -- (Mapper3.west);
\draw[->] (Splitn.east) -- (Mapper4.west);
\draw[->] (Mapper4.east) -- (Reducer1.west);
\draw[->] (Mapper4.east) -- (Reducer2.west);
\draw[->] (Mapper3.east) -- (Reducer1.west);
\draw[->] (Mapper3.east) -- (Reducer2.west);
\draw[->] (Mapper2.east) -- (Reducer1.west);
\draw[->] (Mapper2.east) -- (Reducer2.west);
\draw[->] (Mapper1.east) -- (Reducer1.west);
\draw[->] (Mapper1.east) -- (Reducer2.west);
\draw[->] (Reducer1.east) -- (9,4);
\draw[->] (Reducer2.east) -- (9,1);
\end{tikzpicture}
\figurecaption{Hadoop的MapReduce工作流程图}
\label{fig:HadoopMapReduce}
\end{center}

图\ref{fig:HadoopMapReduce}为Hadoop的MapReduce工作流程图。
从该图中可以发现，MapReduce框架包含两个阶段，map阶段和reduce阶段。
输入数据和计算后的输出数据都是一个(key,value)集合。
用$<k,v>$来表示这些键值对。
key主要用在reduce阶段，用来决定哪个value结合在一起。
用两个函数来表示这两个过程：
\begin{eqnarray}
\mathbf{Mapper} &:& <k1,v1> \rightarrow list<k2,v2> \\
\mathbf{Reduce} &:& <k2,list<v2>> \rightarrow list<k3,v3>
\end{eqnarray}

计算过程从map阶段开始，其中并行执行map函数同时把保存在分布式文件系统的输入数据切分。
进行每次切分就是指定一个map任务。
每个map函数的输出键值对基于中间生成的键进行哈希分区。
然后排序每个分区接着按照键的排序进行合并。
有同样的键的分区被分配到单独的reduce任务中，接着reduce函数输出最终结果。

在Hadoop的MapReduce工作流程中，一个工作记录服务器作为主节点把数据分成几部分作为map阶段的输入。
同时任务记录服务器作为数据节点保存map函数中间生成的结果到HDFS中。
Hadoop会基于地点计划分配MapReduce运算，同时提高集群整体的输入输出效率来减少运算的成本。
